data:
  column_use: data_patterns
  ml_data: distilroberta_sentence_embedding.npy
general:
  device: cuda:0
  random_state: 42
  cache_dir: ../../cache_dir
  data_dir: ../../data
  test_size: 0.3
encoder:
  SentenceEncoder:
    _target_: sentence_transformers.SentenceTransformer
    model_name_or_path: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
    cache_folder: ${general.cache_dir}
    device: ${general.device}
  encode_output: sentence_embedding
  short_name: MiniLM_${encoder.encode_output}
dim_reduce:
  Model: null
classifier:
  Model:
    _target_: catboost.CatBoostClassifier
    _convert_: object
    loss_function: MultiClass
    depth: 9
    iterations: 1000
    learning_rate: 0.01
    early_stopping_rounds: 30
    verbose: false
    task_type: GPU
    random_seed: ${general.random_state}
    custom_loss: F1
