{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "133fa320-756e-4308-8088-016bea4afe27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40f4d3d2-e13e-492f-9f81-2b5d4f33d89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "os.environ['TRANSFORMERS_CACHE'] = './hfcache_proj'\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "cache_dir = \"hfcache_proj\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4a40131-5bb0-4ef1-984b-1b212ae3ae56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from datasets import load_metric, Dataset, DatasetDict\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModelForSequenceClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments\n",
    ")\n",
    "\n",
    "from peft import (\n",
    "    LoraConfig,\n",
    "    get_peft_model\n",
    ")\n",
    "\n",
    "\n",
    "from tqdm.auto import tqdm, trange\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb360af8-e90b-4b82-864d-7b8806b3c29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23ba4b5d-e35e-4095-a457-c664c1e78aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../data/2_preprocessed_data.csv', usecols=['data_patterns', 'Category']).rename(\\\n",
    "    columns={'data_patterns':'text', 'Category': 'label'})\n",
    "\n",
    "le = LabelEncoder()\n",
    "le.fit(df['label'])\n",
    "\n",
    "df['label'] = le.transform(df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a1c710d-e4db-4f09-802d-3f7f1167bfe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stringifying the column: 100%|█| 39772/39772 [00:00<00:00, 512555.68 ex\n",
      "Casting to class labels: 100%|█| 39772/39772 [00:00<00:00, 633505.21 ex\n"
     ]
    }
   ],
   "source": [
    "full_dataset = Dataset.from_pandas(df)\n",
    "full_dataset = full_dataset.class_encode_column(\"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca415064-f386-43db-84ef-ec62dc1134d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = full_dataset.train_test_split(test_size=0.15, stratify_by_column=\"label\")\n",
    "\n",
    "test_dataset = dataset['test']\n",
    "\n",
    "temp_dataset = dataset['train'].train_test_split(test_size=0.2, stratify_by_column=\"label\")\n",
    "val_dataset = temp_dataset['test']\n",
    "train_dataset = temp_dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "60cad0ec-a51c-4a02-94ab-870b61badfc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['label', 'text'],\n",
       "        num_rows: 27044\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['label', 'text'],\n",
       "        num_rows: 6762\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['label', 'text'],\n",
       "        num_rows: 5966\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'validation': val_dataset,\n",
    "    'test': test_dataset\n",
    "})\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2de6c771-ba8b-4d7d-8f96-a2dde0794ad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at ai-forever/ruRoberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"ai-forever/ruRoberta-large\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, cache_dir=cache_dir, device_map=device, )\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=4, cache_dir=cache_dir,\n",
    "                                                           device_map=device, is_decoder=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3ab47410-1276-4efb-bb71-221f9e43e5b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 2,626,564 || all params: 357,990,408 || trainable%: 0.7336967531264134\n"
     ]
    }
   ],
   "source": [
    "config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=16,\n",
    "    target_modules=[\"query\", \"value\"],\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    modules_to_save=[\"classifier\"],\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a1729eb1-457f-40fc-ada2-001dc78356ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████████| 27044/27044 [00:05<00:00, 5246.16 examples/s]\n",
      "Map: 100%|████████████████| 6762/6762 [00:01<00:00, 6083.83 examples/s]\n",
      "Map: 100%|████████████████| 5966/5966 [00:00<00:00, 6281.14 examples/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.map(lambda e:\n",
    "                      tokenizer(e['text'],\n",
    "                                truncation = True,\n",
    "                                max_length=300,\n",
    "                                padding='max_length'), batched=True)\n",
    "\n",
    "\n",
    "dataset = dataset.remove_columns('text')\n",
    "dataset.set_format(type='torch', device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c2e958db-5c53-42d5-8309-535024a49c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка метрики вне функции\n",
    "f1_metric = load_metric(\"f1\")\n",
    "\n",
    "# Параметры обучения\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results_skil_3_lora\",  # Каталог для сохранения результатов обучения\n",
    "    num_train_epochs=10,  # Количество эпох обучения\n",
    "    per_device_train_batch_size=32,  # Размер батча для обучения\n",
    "    per_device_eval_batch_size=16,  # Размер батча для валидации\n",
    "    warmup_steps=400,  # Количество шагов разогрева\n",
    "    weight_decay=0.01,  # Сила L2 регуляризации\n",
    "    logging_dir=\"./runs\",  # Каталог для логов TensorBoard\n",
    "    logging_steps=500,  # Логирование каждые 500 шагов\n",
    "    evaluation_strategy=\"epoch\",  # Стратегия оценки\n",
    "    save_strategy=\"epoch\",  # Стратегия сохранения модели\n",
    "    load_best_model_at_end=True,  # Загрузка лучшей модели в конце\n",
    "    # metric_for_best_model=\"f1\",  # Метрика для выбора лучшей модели\n",
    "    # greater_is_better=True,  # Указывает, что большее значение F1 лучше\n",
    "    no_cuda=False, \n",
    "    dataloader_pin_memory=False,\n",
    "    label_names=[\"labels\"]\n",
    ")\n",
    "\n",
    "# Функция для вычисления метрик\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return f1_metric.compute(predictions=predictions, references=labels, average=\"weighted\")\n",
    "    \n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,  # Модель для обучения\n",
    "    args=training_args,  # Аргументы обучения\n",
    "    train_dataset=dataset[\"train\"],  # Набор данных для обучения\n",
    "    eval_dataset=dataset[\"validation\"],  # Набор данных для валидации\n",
    "    compute_metrics=compute_metrics,  # Метрики для вычисления\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f8960afc-2357-437e-be15-7c3d42d9e7bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8460' max='8460' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8460/8460 1:04:52, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.535600</td>\n",
       "      <td>0.521923</td>\n",
       "      <td>0.798849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.522600</td>\n",
       "      <td>0.507931</td>\n",
       "      <td>0.808700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.495600</td>\n",
       "      <td>0.504487</td>\n",
       "      <td>0.810562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.485800</td>\n",
       "      <td>0.496228</td>\n",
       "      <td>0.810801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.476800</td>\n",
       "      <td>0.491256</td>\n",
       "      <td>0.809526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.463500</td>\n",
       "      <td>0.487192</td>\n",
       "      <td>0.810751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.454200</td>\n",
       "      <td>0.486137</td>\n",
       "      <td>0.815752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.452200</td>\n",
       "      <td>0.487222</td>\n",
       "      <td>0.814514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.453100</td>\n",
       "      <td>0.484713</td>\n",
       "      <td>0.814181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.452300</td>\n",
       "      <td>0.483156</td>\n",
       "      <td>0.814824</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=8460, training_loss=0.4772305066985723, metrics={'train_runtime': 3893.7573, 'train_samples_per_second': 69.455, 'train_steps_per_second': 2.173, 'total_flos': 1.48954305784896e+17, 'train_loss': 0.4772305066985723, 'epoch': 10.0})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dad62a53-46e7-442c-954e-d26c1747ec28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "PredictionOutput(predictions=array([[ 2.6408105 ,  1.4095021 , -1.7025145 , -3.7913508 ],\n",
       "       [ 1.1955377 , -1.013178  ,  0.3954386 , -1.9937655 ],\n",
       "       [ 1.982578  ,  1.0721871 , -0.3338479 , -3.5502372 ],\n",
       "       ...,\n",
       "       [ 3.8960667 , -0.7571025 , -0.79035205, -3.175102  ],\n",
       "       [ 1.5289737 ,  0.5212045 ,  0.37871343, -3.2820044 ],\n",
       "       [-0.04937939,  2.91227   , -1.4072332 , -2.3378756 ]],\n",
       "      dtype=float32), label_ids=array([1, 0, 0, ..., 0, 1, 1]), metrics={'test_loss': 0.4879555106163025, 'test_f1': 0.8136142085151359, 'test_runtime': 36.2537, 'test_samples_per_second': 164.563, 'test_steps_per_second': 10.289})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.predict(dataset[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0fb381cd-52bd-4e08-8ec9-f97e6e8844b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  model_path = \"./skil_save_3_lora\"\n",
    "#  trainer.save_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60fc9a31-b5e9-4b4f-b04a-a8d5225861a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
